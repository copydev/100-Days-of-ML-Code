{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classifier\n",
    "##### MNIST classifier using Convolutional Neural Network\n",
    "##### Link to official tutorial: https://www.tensorflow.org/versions/r1.2/get_started/mnist/pros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load mnist data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow for obvious reasons\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for input data\n",
    "# data will be fed into tensorflow placeholder once a session is run\n",
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create weights ad biases with a small amount of noise\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution and pooling\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights and biases\n",
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "W_fc1 = weight_variable([3136,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "W_fc2 = weight_variable([1024,512])\n",
    "b_fc2 = bias_variable([512])\n",
    "W_fc3 = weight_variable([512,10])\n",
    "b_fc3 = bias_variable([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape x\n",
    "x_images = tf.reshape(x, shape=[-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dropout to conv layers\n",
    "keep_prob_conv = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv layer 1\n",
    "h_conv1 = conv2d(x_images, W_conv1)\n",
    "h_conv1_activated = tf.nn.relu(h_conv1 + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1_activated)\n",
    "h_pool1_dropout = tf.nn.dropout(h_pool1, keep_prob_conv)\n",
    "# conv layer 2\n",
    "h_conv2 = conv2d(h_pool1_dropout, W_conv2)\n",
    "h_conv2_activated = tf.nn.relu(h_conv2 + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2_activated)\n",
    "h_pool2_dropout = tf.nn.dropout(h_pool2, keep_prob_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten output from conv layers\n",
    "x_fc = tf.reshape(h_pool2, shape=[-1, 7*7*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dropout to fc layers\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully conected layer 1\n",
    "h_fc1 = tf.matmul(x_fc, W_fc1) + b_fc1\n",
    "h_fc1_activated = tf.nn.relu(h_fc1)\n",
    "h_fc1_dropout = tf.nn.dropout(h_fc1_activated, keep_prob)\n",
    "# fully conected layer 2\n",
    "h_fc2 = tf.matmul(h_fc1_dropout, W_fc2)\n",
    "h_fc2_activated = tf.nn.relu(h_fc2)\n",
    "h_fc2_dropout = tf.nn.dropout(h_fc2_activated, keep_prob)\n",
    "# fully conected layer 3\n",
    "y = tf.matmul(h_fc2_dropout, W_fc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder to input correct answers\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cost function \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y, labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the tensorflow computational graph to minimize the cost using gradient descent\n",
    "train = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tensorflow interactive session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables inside the graph\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 30, loss: 1099.911477714777\n",
      "Epoch 2 out of 30, loss: 199.05607546120882\n",
      "Epoch 3 out of 30, loss: 126.77534003928304\n",
      "Epoch 4 out of 30, loss: 96.00221067667007\n",
      "Epoch 5 out of 30, loss: 78.03182378411293\n",
      "Epoch 6 out of 30, loss: 69.88709651771933\n",
      "Epoch 7 out of 30, loss: 60.6324864840135\n",
      "Epoch 8 out of 30, loss: 54.239332656841725\n",
      "Epoch 9 out of 30, loss: 47.37119508301839\n",
      "Epoch 10 out of 30, loss: 45.24328855331987\n",
      "Epoch 11 out of 30, loss: 42.27774349111132\n",
      "Epoch 12 out of 30, loss: 39.34553468413651\n",
      "Epoch 13 out of 30, loss: 36.46979158301838\n",
      "Epoch 14 out of 30, loss: 34.59762412670534\n",
      "Epoch 15 out of 30, loss: 33.16444252850488\n",
      "Epoch 16 out of 30, loss: 31.264316155808046\n",
      "Epoch 17 out of 30, loss: 31.819046836462803\n",
      "Epoch 18 out of 30, loss: 29.074158981675282\n",
      "Epoch 19 out of 30, loss: 30.246673419489525\n",
      "Epoch 20 out of 30, loss: 26.465616556815803\n",
      "Epoch 21 out of 30, loss: 26.42076426348649\n",
      "Epoch 22 out of 30, loss: 25.39834358112421\n",
      "Epoch 23 out of 30, loss: 26.453604583395645\n",
      "Epoch 24 out of 30, loss: 24.594339015777223\n",
      "Epoch 25 out of 30, loss: 23.548220804485027\n",
      "Epoch 26 out of 30, loss: 23.44599934964208\n",
      "Epoch 27 out of 30, loss: 23.87452809367096\n",
      "Epoch 28 out of 30, loss: 21.863940235896735\n",
      "Epoch 29 out of 30, loss: 21.372184407751774\n",
      "Epoch 30 out of 30, loss: 21.61112796794623\n"
     ]
    }
   ],
   "source": [
    "# train the model! (uses mini-batch)\n",
    "num_epochs = 30\n",
    "batch_size = 100\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        t, c = sess.run([train, cost], feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 0.5, keep_prob_conv: 0.25})\n",
    "        epoch_loss += c\n",
    "    print(f\"Epoch {epoch+1} out of {num_epochs}, loss: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict output using our model\n",
    "# returns a boolean array\n",
    "predictions = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast the boolean array to float and calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9889\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0, keep_prob_conv: 0.25}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 98.89% accuracy is ot that bad. Best models can get to over 99.7% accuracy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
