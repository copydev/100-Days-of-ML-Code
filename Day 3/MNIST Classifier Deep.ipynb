{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classifier\n",
    "##### A simple MNIST classifier using a Deep Neural Network\n",
    "##### Link to official tutorial: https://www.tensorflow.org/versions/r1.2/get_started/mnist/beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load mnist data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow for obvious reasons\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for input data\n",
    "# data will be fed into tensorflow placeholder once a session is run\n",
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise weights and biases as a tensor of zeros\n",
    "W1 = tf.Variable(tf.random_normal([784, 512]))\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "W2 = tf.Variable(tf.random_normal([512, 512]))\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "W3 = tf.Variable(tf.random_normal([512, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform dot product of inputs and weights and add bias\n",
    "layer1 = tf.matmul(x, W1) + b1\n",
    "layer1_activated = tf.nn.relu(layer1)\n",
    "layer2 = tf.matmul(layer1_activated, W2) + b2\n",
    "layer2_activated = tf.nn.relu(layer2)\n",
    "output = tf.matmul(layer2_activated, W3) + b3\n",
    "y = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder to input correct answers\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cost function \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y, labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the tensorflow computational graph to minimize the cost using gradient descent\n",
    "train = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tensorflow interactive session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables inside the graph\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 200, loss: 145437.4255809784\n",
      "Epoch 2 out of 200, loss: 33522.61598968506\n",
      "Epoch 3 out of 200, loss: 19464.536337435246\n",
      "Epoch 4 out of 200, loss: 12500.409530714154\n",
      "Epoch 5 out of 200, loss: 8337.979229713903\n",
      "Epoch 6 out of 200, loss: 5688.745858082266\n",
      "Epoch 7 out of 200, loss: 3723.4547630222455\n",
      "Epoch 8 out of 200, loss: 2651.9821398926124\n",
      "Epoch 9 out of 200, loss: 1992.7077482770565\n",
      "Epoch 10 out of 200, loss: 1474.6007340562685\n",
      "Epoch 11 out of 200, loss: 1179.476228363523\n",
      "Epoch 12 out of 200, loss: 1048.9216850737566\n",
      "Epoch 13 out of 200, loss: 906.6193003596536\n",
      "Epoch 14 out of 200, loss: 851.9380919688134\n",
      "Epoch 15 out of 200, loss: 715.9516718656614\n",
      "Epoch 16 out of 200, loss: 788.5997553646451\n",
      "Epoch 17 out of 200, loss: 892.7152502991981\n",
      "Epoch 18 out of 200, loss: 605.3213364770196\n",
      "Epoch 19 out of 200, loss: 533.8620711769295\n",
      "Epoch 20 out of 200, loss: 590.580702703235\n",
      "Epoch 21 out of 200, loss: 491.33168884671977\n",
      "Epoch 22 out of 200, loss: 610.1164316661162\n",
      "Epoch 23 out of 200, loss: 578.007199764037\n",
      "Epoch 24 out of 200, loss: 339.43589835336127\n",
      "Epoch 25 out of 200, loss: 495.8080098169088\n",
      "Epoch 26 out of 200, loss: 674.4774030016099\n",
      "Epoch 27 out of 200, loss: 347.1673827101518\n",
      "Epoch 28 out of 200, loss: 356.1291040742917\n",
      "Epoch 29 out of 200, loss: 329.9913717509822\n",
      "Epoch 30 out of 200, loss: 547.5511169010173\n",
      "Epoch 31 out of 200, loss: 460.3757292578791\n",
      "Epoch 32 out of 200, loss: 289.436233856241\n",
      "Epoch 33 out of 200, loss: 351.66945636870054\n",
      "Epoch 34 out of 200, loss: 348.0255291560103\n",
      "Epoch 35 out of 200, loss: 323.05752759166967\n",
      "Epoch 36 out of 200, loss: 341.7737411393728\n",
      "Epoch 37 out of 200, loss: 334.5959900951216\n",
      "Epoch 38 out of 200, loss: 359.7352912946324\n",
      "Epoch 39 out of 200, loss: 271.0673198776112\n",
      "Epoch 40 out of 200, loss: 378.4619010636378\n",
      "Epoch 41 out of 200, loss: 319.03806937635807\n",
      "Epoch 42 out of 200, loss: 279.23825236099975\n",
      "Epoch 43 out of 200, loss: 343.36366258586514\n",
      "Epoch 44 out of 200, loss: 270.73822846900293\n",
      "Epoch 45 out of 200, loss: 319.80407233703545\n",
      "Epoch 46 out of 200, loss: 281.09216215125065\n",
      "Epoch 47 out of 200, loss: 252.99768021391435\n",
      "Epoch 48 out of 200, loss: 221.4943700995445\n",
      "Epoch 49 out of 200, loss: 206.50327791813848\n",
      "Epoch 50 out of 200, loss: 215.86483651859663\n",
      "Epoch 51 out of 200, loss: 232.69058427030686\n",
      "Epoch 52 out of 200, loss: 255.84787539459217\n",
      "Epoch 53 out of 200, loss: 259.86164240319647\n",
      "Epoch 54 out of 200, loss: 201.49287924720622\n",
      "Epoch 55 out of 200, loss: 165.00259421701014\n",
      "Epoch 56 out of 200, loss: 245.28183254072582\n",
      "Epoch 57 out of 200, loss: 238.59810119091247\n",
      "Epoch 58 out of 200, loss: 228.43123970888473\n",
      "Epoch 59 out of 200, loss: 232.93198144488224\n",
      "Epoch 60 out of 200, loss: 189.13033947598578\n",
      "Epoch 61 out of 200, loss: 170.53146319119588\n",
      "Epoch 62 out of 200, loss: 212.7993302773268\n",
      "Epoch 63 out of 200, loss: 220.80007586320576\n",
      "Epoch 64 out of 200, loss: 158.33472997400506\n",
      "Epoch 65 out of 200, loss: 196.29972557724022\n",
      "Epoch 66 out of 200, loss: 140.63055013057334\n",
      "Epoch 67 out of 200, loss: 151.36429700031618\n",
      "Epoch 68 out of 200, loss: 309.97807013782165\n",
      "Epoch 69 out of 200, loss: 168.22798337438869\n",
      "Epoch 70 out of 200, loss: 144.08284113576752\n",
      "Epoch 71 out of 200, loss: 151.11071999748083\n",
      "Epoch 72 out of 200, loss: 151.74011675108898\n",
      "Epoch 73 out of 200, loss: 143.75484663928702\n",
      "Epoch 74 out of 200, loss: 193.97746526248972\n",
      "Epoch 75 out of 200, loss: 178.91465098055065\n",
      "Epoch 76 out of 200, loss: 140.38840471902114\n",
      "Epoch 77 out of 200, loss: 188.171524500237\n",
      "Epoch 78 out of 200, loss: 171.96258254124825\n",
      "Epoch 79 out of 200, loss: 100.58769986880012\n",
      "Epoch 80 out of 200, loss: 114.45775813498875\n",
      "Epoch 81 out of 200, loss: 144.35386206013936\n",
      "Epoch 82 out of 200, loss: 155.9275967961036\n",
      "Epoch 83 out of 200, loss: 211.887194171792\n",
      "Epoch 84 out of 200, loss: 130.43237299058026\n",
      "Epoch 85 out of 200, loss: 89.85681207658126\n",
      "Epoch 86 out of 200, loss: 131.6212457326293\n",
      "Epoch 87 out of 200, loss: 156.32327954024913\n",
      "Epoch 88 out of 200, loss: 192.28330537950387\n",
      "Epoch 89 out of 200, loss: 84.79304546820491\n",
      "Epoch 90 out of 200, loss: 131.61904948676238\n",
      "Epoch 91 out of 200, loss: 171.45843069279363\n",
      "Epoch 92 out of 200, loss: 171.1261543227732\n",
      "Epoch 93 out of 200, loss: 92.39822832312362\n",
      "Epoch 94 out of 200, loss: 130.85903141818082\n",
      "Epoch 95 out of 200, loss: 93.70379861428306\n",
      "Epoch 96 out of 200, loss: 197.3922197761684\n",
      "Epoch 97 out of 200, loss: 228.16870717328896\n",
      "Epoch 98 out of 200, loss: 80.21584445714946\n",
      "Epoch 99 out of 200, loss: 192.27953817496223\n",
      "Epoch 100 out of 200, loss: 192.74659460339743\n",
      "Epoch 101 out of 200, loss: 120.52920986508768\n",
      "Epoch 102 out of 200, loss: 82.46763490689257\n",
      "Epoch 103 out of 200, loss: 77.84505783383803\n",
      "Epoch 104 out of 200, loss: 151.88059183021844\n",
      "Epoch 105 out of 200, loss: 175.98510176214953\n",
      "Epoch 106 out of 200, loss: 155.13529456475953\n",
      "Epoch 107 out of 200, loss: 148.72270308849664\n",
      "Epoch 108 out of 200, loss: 94.79788837491867\n",
      "Epoch 109 out of 200, loss: 96.26168851096651\n",
      "Epoch 110 out of 200, loss: 110.65861877669892\n",
      "Epoch 111 out of 200, loss: 61.36336903057236\n",
      "Epoch 112 out of 200, loss: 189.9671148021589\n",
      "Epoch 113 out of 200, loss: 133.88911772275094\n",
      "Epoch 114 out of 200, loss: 90.15445176795541\n",
      "Epoch 115 out of 200, loss: 109.29780221655871\n",
      "Epoch 116 out of 200, loss: 99.31638321664514\n",
      "Epoch 117 out of 200, loss: 73.32636802395109\n",
      "Epoch 118 out of 200, loss: 105.35031020493912\n",
      "Epoch 119 out of 200, loss: 137.6929665500233\n",
      "Epoch 120 out of 200, loss: 199.61603657322652\n",
      "Epoch 121 out of 200, loss: 78.60497091114519\n",
      "Epoch 122 out of 200, loss: 94.53215028386826\n",
      "Epoch 123 out of 200, loss: 144.2267468712289\n",
      "Epoch 124 out of 200, loss: 94.52286637392109\n",
      "Epoch 125 out of 200, loss: 120.7271108963061\n",
      "Epoch 126 out of 200, loss: 103.65968477709472\n",
      "Epoch 127 out of 200, loss: 131.70709170921828\n",
      "Epoch 128 out of 200, loss: 132.4578928017865\n",
      "Epoch 129 out of 200, loss: 68.04292475571856\n",
      "Epoch 130 out of 200, loss: 70.96724344909191\n",
      "Epoch 131 out of 200, loss: 128.85781073849284\n",
      "Epoch 132 out of 200, loss: 136.94653924558057\n",
      "Epoch 133 out of 200, loss: 67.37287354841828\n",
      "Epoch 134 out of 200, loss: 116.07223029716289\n",
      "Epoch 135 out of 200, loss: 73.3682024607935\n",
      "Epoch 136 out of 200, loss: 88.21274400166394\n",
      "Epoch 137 out of 200, loss: 84.98025053709716\n",
      "Epoch 138 out of 200, loss: 95.40314667403698\n",
      "Epoch 139 out of 200, loss: 102.39643716573136\n",
      "Epoch 140 out of 200, loss: 129.17439566433413\n",
      "Epoch 141 out of 200, loss: 88.08047993341461\n",
      "Epoch 142 out of 200, loss: 79.79439087507208\n",
      "Epoch 143 out of 200, loss: 132.78181546926498\n",
      "Epoch 144 out of 200, loss: 53.93793070316315\n",
      "Epoch 145 out of 200, loss: 124.02685604989529\n",
      "Epoch 146 out of 200, loss: 96.99844095702923\n",
      "Epoch 147 out of 200, loss: 151.5562637009225\n",
      "Epoch 148 out of 200, loss: 111.55867301984745\n",
      "Epoch 149 out of 200, loss: 83.58318112041752\n",
      "Epoch 150 out of 200, loss: 64.78989692288525\n",
      "Epoch 151 out of 200, loss: 143.3395072558974\n",
      "Epoch 152 out of 200, loss: 109.78722617182487\n",
      "Epoch 153 out of 200, loss: 46.80843561301299\n",
      "Epoch 154 out of 200, loss: 92.88075891137123\n",
      "Epoch 155 out of 200, loss: 128.30525529969484\n",
      "Epoch 156 out of 200, loss: 101.4836001589249\n",
      "Epoch 157 out of 200, loss: 90.85244173184037\n",
      "Epoch 158 out of 200, loss: 37.3748324662447\n",
      "Epoch 159 out of 200, loss: 48.96846092104661\n",
      "Epoch 160 out of 200, loss: 115.64026298182623\n",
      "Epoch 161 out of 200, loss: 128.71609895728528\n",
      "Epoch 162 out of 200, loss: 142.67521851933785\n",
      "Epoch 163 out of 200, loss: 98.86581558972597\n",
      "Epoch 164 out of 200, loss: 22.603864144227607\n",
      "Epoch 165 out of 200, loss: 29.485345337059698\n",
      "Epoch 166 out of 200, loss: 116.55506898580694\n",
      "Epoch 167 out of 200, loss: 116.80251130327582\n",
      "Epoch 168 out of 200, loss: 68.30185515855439\n",
      "Epoch 169 out of 200, loss: 54.659569177478545\n",
      "Epoch 170 out of 200, loss: 67.91180550738451\n",
      "Epoch 171 out of 200, loss: 108.47105113626935\n",
      "Epoch 172 out of 200, loss: 87.34564244951713\n",
      "Epoch 173 out of 200, loss: 91.97825978904504\n",
      "Epoch 174 out of 200, loss: 132.50759820522734\n",
      "Epoch 175 out of 200, loss: 72.08964028954506\n",
      "Epoch 176 out of 200, loss: 62.41288543437622\n",
      "Epoch 177 out of 200, loss: 89.95973078997935\n",
      "Epoch 178 out of 200, loss: 101.0327409889469\n",
      "Epoch 179 out of 200, loss: 73.6577422618866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 out of 200, loss: 75.97101832888438\n",
      "Epoch 181 out of 200, loss: 53.50108038846403\n",
      "Epoch 182 out of 200, loss: 76.38282419729512\n",
      "Epoch 183 out of 200, loss: 73.1136952067609\n",
      "Epoch 184 out of 200, loss: 89.4492637142539\n",
      "Epoch 185 out of 200, loss: 103.33458541257642\n",
      "Epoch 186 out of 200, loss: 40.31813018262386\n",
      "Epoch 187 out of 200, loss: 79.91770489606154\n",
      "Epoch 188 out of 200, loss: 94.85358714312315\n",
      "Epoch 189 out of 200, loss: 83.98040870070457\n",
      "Epoch 190 out of 200, loss: 107.01792446350163\n",
      "Epoch 191 out of 200, loss: 28.218840995046776\n",
      "Epoch 192 out of 200, loss: 61.46475591718627\n",
      "Epoch 193 out of 200, loss: 37.0376925264718\n",
      "Epoch 194 out of 200, loss: 126.67246499385078\n",
      "Epoch 195 out of 200, loss: 95.24388513937447\n",
      "Epoch 196 out of 200, loss: 60.65972638404001\n",
      "Epoch 197 out of 200, loss: 92.50722402349066\n",
      "Epoch 198 out of 200, loss: 104.28186093382828\n",
      "Epoch 199 out of 200, loss: 53.585700847792054\n",
      "Epoch 200 out of 200, loss: 104.82379472799599\n"
     ]
    }
   ],
   "source": [
    "# train the model! (using Stochastic Gradient Descent)\n",
    "num_epochs = 200\n",
    "batch_size = 100\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        t, c = sess.run([train, cost], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        epoch_loss += c\n",
    "    print(f\"Epoch {epoch+1} out of {num_epochs}, loss: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict output using our model\n",
    "# returns a boolean array\n",
    "predictions = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast the boolean array to float and calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9788\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 97.88% accuracy is pretty bad. Best models can get to over 99.7% accuracy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
